{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l_san\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms= spark.read.csv('../Datasets/SMS.csv', header=True, inferSchema=True, nullValue='NA', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-----+\n",
      "|Index|                Text|Label|\n",
      "+-----+--------------------+-----+\n",
      "|    1|Sorry, I'll call ...|    0|\n",
      "|    2|Dont worry. I gue...|    0|\n",
      "|    3|Call FREEPHONE 08...|    1|\n",
      "|    4|Win a 1000 cash p...|    1|\n",
      "|    5|Go until jurong p...|    0|\n",
      "+-----+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = sms.withColumn('Text', regexp_replace(sms.Text, '[_():;,.]', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = sms.withColumn('Text', regexp_replace(sms.Text, '[0-9]', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------------------------------------------------------------+-----+\n",
      "|Index|Text                                                                                                           |Label|\n",
      "+-----+---------------------------------------------------------------------------------------------------------------+-----+\n",
      "|1    |Sorry  I'll call later in meeting                                                                              |0    |\n",
      "|2    |Dont worry  I guess he's busy                                                                                  |0    |\n",
      "|3    |Call FREEPHONE               now!                                                                              |1    |\n",
      "|4    |Win a      cash prize or a prize worth                                                                         |1    |\n",
      "|5    |Go until jurong point  crazy   Available only in bugis n great world la e buffet    Cine there got amore wat   |0    |\n",
      "+-----+---------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = Tokenizer(inputCol='Text', outputCol='Text Tokens').transform(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------+-----+---------------------------------------------------+\n",
      "|Index|Text                             |Label|Text Tokens                                        |\n",
      "+-----+---------------------------------+-----+---------------------------------------------------+\n",
      "|1    |Sorry  I'll call later in meeting|0    |[sorry, , i'll, call, later, in, meeting]          |\n",
      "|2    |Dont worry  I guess he's busy    |0    |[dont, worry, , i, guess, he's, busy]              |\n",
      "|3    |Call FREEPHONE               now!|1    |[call, freephone, , , , , , , , , , , , , , , now!]|\n",
      "+-----+---------------------------------+-----+---------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop= StopWordsRemover(inputCol='Text Tokens', outputCol= 'Tokens stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = stop.transform(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-----+--------------------+--------------------+\n",
      "|Index|                Text|Label|         Text Tokens|         Tokens stop|\n",
      "+-----+--------------------+-----+--------------------+--------------------+\n",
      "|    1|Sorry  I'll call ...|    0|[sorry, , i'll, c...|[sorry, , call, l...|\n",
      "|    2|Dont worry  I gue...|    0|[dont, worry, , i...|[dont, worry, , g...|\n",
      "+-----+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher= HashingTF(inputCol='Tokens stop', outputCol='Tokens hash', numFeatures=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = hasher.transform(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------+-----+-----------------------------------------+-------------------------------+-------------------------------------------+\n",
      "|Index|Text                             |Label|Text Tokens                              |Tokens stop                    |Tokens hash                                |\n",
      "+-----+---------------------------------+-----+-----------------------------------------+-------------------------------+-------------------------------------------+\n",
      "|1    |Sorry  I'll call later in meeting|0    |[sorry, , i'll, call, later, in, meeting]|[sorry, , call, later, meeting]|(50,[10,20,22,37,46],[1.0,1.0,1.0,1.0,1.0])|\n",
      "+-----+---------------------------------+-----+-----------------------------------------+-------------------------------+-------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol='Tokens hash', outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = idf.fit(sms).transform(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------+-----+----------------------------------------------------+---------------------------------------------------+-------------------------------------------+---------------------------------------------------------------------------------------------------------------------+\n",
      "|Index|Text                                       |Label|Text Tokens                                         |Tokens stop                                        |Tokens hash                                |features                                                                                                             |\n",
      "+-----+-------------------------------------------+-----+----------------------------------------------------+---------------------------------------------------+-------------------------------------------+---------------------------------------------------------------------------------------------------------------------+\n",
      "|1    |Sorry  I'll call later in meeting          |0    |[sorry, , i'll, call, later, in, meeting]           |[sorry, , call, later, meeting]                    |(50,[10,20,22,37,46],[1.0,1.0,1.0,1.0,1.0])|(50,[10,20,22,37,46],[1.5309832190411887,2.118769883943308,0.3295010760277046,1.7273330619983314,1.5434990269730196])|\n",
      "|2    |Dont worry  I guess he's busy              |0    |[dont, worry, , i, guess, he's, busy]               |[dont, worry, , guess, busy]                       |(50,[10,22,27,43],[1.0,1.0,2.0,1.0])       |(50,[10,22,27,43],[1.5309832190411887,0.3295010760277046,3.701363010783856,2.001982368528426])                       |\n",
      "|3    |Call FREEPHONE               now!          |1    |[call, freephone, , , , , , , , , , , , , , , now!] |[call, freephone, , , , , , , , , , , , , , , now!]|(50,[7,22,38,46],[1.0,14.0,1.0,1.0])       |(50,[7,22,38,46],[1.6257131360530892,4.613015064387865,1.758073187358027,1.5434990269730196])                        |\n",
      "|4    |Win a      cash prize or a prize worth     |1    |[win, a, , , , , , cash, prize, or, a, prize, worth]|[win, , , , , , cash, prize, prize, worth]         |(50,[13,22,29,48],[3.0,5.0,1.0,1.0])       |(50,[13,22,29,48],[5.835578752614313,1.647505380138523,2.019397410130104,1.97835922276499])                          |\n",
      "+-----+-------------------------------------------+-----+----------------------------------------------------+---------------------------------------------------+-------------------------------------------+---------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_train, sms_test= sms.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg= LogisticRegression(labelCol='Label', regParam=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg =logreg.fit(sms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_train_log= logreg.transform(sms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|Label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|  323|\n",
      "|    0|       0.0| 3789|\n",
      "|    1|       1.0|  263|\n",
      "|    0|       1.0|   29|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms_train_log.groupby('Label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_evaluator= BinaryClassificationEvaluator(labelCol='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc= binary_evaluator.evaluate(sms_train_log, {binary_evaluator.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9566707995358837"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-----+\n",
      "|Index|                Text|Label|\n",
      "+-----+--------------------+-----+\n",
      "|    1|Sorry, I'll call ...|    0|\n",
      "|    2|Dont worry. I gue...|    0|\n",
      "+-----+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms  = sms.withColumn('Text', regexp_replace(sms.Text, '[_,().-?;]', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = sms.withColumn('Text', regexp_replace(sms.Text, '[0-9]', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= Tokenizer(inputCol='Text', outputCol='Text_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = StopWordsRemover(inputCol='Text_tokens', outputCol='Text_stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hasher = HashingTF(inputCol='Text_stop', outputCol='Text_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF = IDF(inputCol='Text_hash', outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(labelCol='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer, stop_words, Hasher, IDF, logreg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ParamGridBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params.addGrid(Hasher.numFeatures, [1024, 4096, 16384]).addGrid(Hasher.binary, [True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params.addGrid(logreg.elasticNetParam, [0.0, 0.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params.addGrid(logreg.regParam, [0.01, 0.1, 1 ,10]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps= params, evaluator=evaluator , numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_train, sms_test= sms.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cv.fit(sms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9751875438826991,\n",
       " 0.9811754337589402,\n",
       " 0.9826785095221335,\n",
       " 0.980869218656339,\n",
       " 0.9738757415256927,\n",
       " 0.9398181230394758,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9715581062563425,\n",
       " 0.8781817678005299,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9771470010424326,\n",
       " 0.9825159727319974,\n",
       " 0.9835908454194657,\n",
       " 0.9815695366872039,\n",
       " 0.977451722564183,\n",
       " 0.9581489541227295,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9744066323531408,\n",
       " 0.9367849153275196,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9865449527723238,\n",
       " 0.9891755856386719,\n",
       " 0.9907124890009102,\n",
       " 0.9904277835561638,\n",
       " 0.9768938926136608,\n",
       " 0.9422826165856779,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9750921239235215,\n",
       " 0.8712171458088867,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.985703208502408,\n",
       " 0.9885753688466101,\n",
       " 0.9901752541338755,\n",
       " 0.9900423766082309,\n",
       " 0.9789621161055408,\n",
       " 0.9611631093618633,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9744118806099786,\n",
       " 0.9365763653153372,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9917557823075693,\n",
       " 0.992382531488428,\n",
       " 0.9922340286552813,\n",
       " 0.9914650743494082,\n",
       " 0.9766149130597428,\n",
       " 0.941936846435304,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9750774240762172,\n",
       " 0.8920875443488225,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9910008988282544,\n",
       " 0.9916346461588723,\n",
       " 0.9914939363874862,\n",
       " 0.9909717078455682,\n",
       " 0.9800644691097692,\n",
       " 0.963156871730295,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.9749747634034946,\n",
       " 0.9365887110316955,\n",
       " 0.5,\n",
       " 0.5]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe = scores.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log= best_pipe.stages[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_dbec1ad5e05b', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2,\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0,\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto',\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='featuresCol', doc='features column name.'): 'features',\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='fitIntercept', doc='whether to fit an intercept term.'): True,\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='labelCol', doc='label column name.'): 'Label',\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0,\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='maxIter', doc='max number of iterations (>= 0).'): 100,\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability',\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction',\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='regParam', doc='regularization parameter (>= 0).'): 0.1,\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='standardization', doc='whether to standardize the training features before fitting the model.'): True,\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5,\n",
       " Param(parent='LogisticRegression_dbec1ad5e05b', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = best_pipe.transform(sms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966444239914097"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
